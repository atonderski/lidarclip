{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import itertools\n",
    "from functools import partial\n",
    "from typing import Dict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "sys.path.append('..')\n",
    "from lidarclip.anno_loader import build_anno_loader, CLASSES, WEATHERS\n",
    "from lidarclip.helpers import MultiLoader, try_paths, logit_img_txt\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidarclip.prompts import OBJECT_PROMPT_TEMPLATES\n",
    "print(\"Num prompts per subcategory:\")\n",
    "print(f\"  Objects: {len(OBJECT_PROMPT_TEMPLATES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP_VERSION = \"ViT-L/14\"\n",
    "CLIP_VERSION = \"ViT-L/14\"\n",
    "\n",
    "# Load data and features\n",
    "batch_size = 1\n",
    "clip_model, clip_preprocess = clip.load(CLIP_VERSION)\n",
    "feature_version = CLIP_VERSION.lower().replace(\"/\", \"-\")\n",
    "feature_root = try_paths(\"/proj/nlp4adas/features\", \"../features\")\n",
    "obj_feats = torch.load(f\"{feature_root}/once_{feature_version}_val_lidar_objs.pt\", map_location=device)\n",
    "for class_name, cls_feats in obj_feats.items():\n",
    "    print(class_name, len(cls_feats))\n",
    "    obj_feats[class_name] = torch.stack(cls_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = CLASSES\n",
    "def gen_cls_embedding(cls_name: str) -> torch.Tensor:\n",
    "    print(f\"Generating embedding for {cls_name}\")\n",
    "    prompts = [template.format(cls_name) for template in OBJECT_PROMPT_TEMPLATES]\n",
    "    # if cls_name == \"Car\":\n",
    "    #     cls_name = \"Vehicle\"\n",
    "    prompts = [f\"A photo of a {cls_name} on the street or in the city\"]\n",
    "    with torch.no_grad():\n",
    "        tokenized_prompts = clip.tokenize(prompts).to(device)\n",
    "        cls_features = clip_model.encode_text(tokenized_prompts)\n",
    "        return cls_features.sum(axis=0, keepdim=True)\n",
    "cls_embeddings = {name: gen_cls_embedding(name) for name in CATEGORIES}\n",
    "print(\"Generated embeddings for: \", list(cls_embeddings.keys()))\n",
    "cls_embeddings_pt = torch.vstack(list(cls_embeddings.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def compute_accuracy(obj_feats: torch.Tensor, tru_class_idx: int) -> Dict[str, float]:\n",
    "    logits_per_text, _ = logit_img_txt(obj_feats, cls_embeddings_pt, clip_model)\n",
    "    score_per_class = logits_per_text.softmax(0).T\n",
    "    accuracies = {}\n",
    "    for k in range(1, min(6, score_per_class.shape[1]+1)):\n",
    "        topk = (score_per_class.argsort(axis=1, descending=True)[:, :k] == tru_class_idx).sum() / len(score_per_class)\n",
    "        accuracies[f\"top-{k}\"] = topk\n",
    "    return accuracies\n",
    "\n",
    "overall_clsavg = defaultdict(float)\n",
    "overall_objavg = defaultdict(float)\n",
    "for class_name, cls_obj_feats in obj_feats.items():\n",
    "    if class_name not in CATEGORIES:\n",
    "        continue\n",
    "    print(\"Evaluating class\", class_name, f\"(n={len(cls_obj_feats)})\")\n",
    "    accuracies = compute_accuracy(cls_obj_feats, CATEGORIES.index(class_name))\n",
    "    res_string = \", \".join(f\"{k}: {v:.3f} ({v*100:.1f}%)\" for k, v in accuracies.items())\n",
    "    print(f\"  {res_string}\")\n",
    "    for k, v in accuracies.items():\n",
    "        overall_clsavg[k] += v\n",
    "        overall_objavg[k] += v * len(cls_obj_feats)\n",
    "\n",
    "print(f\"\\nOverall (cls avg):\")\n",
    "overall_clsavg = {k: v / len(CATEGORIES) for k, v in overall_clsavg.items()}\n",
    "res_string = \", \".join(f\"{k}: {v:.3f} ({v*100:.1f}%)\" for k, v in overall_clsavg.items())\n",
    "print(f\"  {res_string}\")\n",
    "\n",
    "print(\"\\nOverall (obj avg)\")\n",
    "num_objs = sum(len(v) for v in obj_feats.values())\n",
    "overall_objavg = {k: v / num_objs for k, v in overall_objavg.items()}\n",
    "res_string = \", \".join(f\"{k}: {v:.3f} ({v*100:.1f}%)\" for k, v in overall_objavg.items())\n",
    "print(f\"  {res_string}\")\n",
    "\n",
    "print(\"\\nOverall if guessing randomly:\")\n",
    "# Compute the probability of guessing correctly by chance\n",
    "rand_acc = 1 / len(CATEGORIES)\n",
    "res_string = \", \".join(f\"{k}: {v:.3f} ({v*100:.1f}%)\" for k, v in {k: rand_acc*int(k.split(\"-\")[1]) for k in overall}.items())\n",
    "print(f\"  {res_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8474fbf7fa6f299d9ca87dcd7358dfc28aa95d8ec78802489d98a6cd3ecc0cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
