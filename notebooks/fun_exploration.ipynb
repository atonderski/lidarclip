{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import clip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "sys.path.append('..')\n",
    "from lidar_clippin.loader import build_loader\n",
    "from lidar_clippin.anno_loader import build_anno_loader, CLASSES, WEATHERS\n",
    "from lidar_clippin.helpers import MultiLoader, try_paths, get_topk, get_topk_separate_prompts, logit_img_txt\n",
    "from lidar_clippin.prompts import WEATHER_PROMPT_TEMPLATES, PERIOD_PROMPT_TEMPLATES, OBJECT_PROMPT_TEMPLATES, BUSY_PROMPTS, EMPTY_PROMPTS\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_VERSION = \"ViT-L/14\"\n",
    "USE_COSINE = False\n",
    "SPLITS = [\"val\", \"test\"]\n",
    "DATASET_NAME = \"once\"\n",
    "\n",
    "# Load clip\n",
    "clip_model, clip_preprocess = clip.load(CLIP_VERSION)\n",
    "get_topk = partial(get_topk, clip_model=clip_model, device=device)\n",
    "get_topk_separate_prompts = partial(get_topk_separate_prompts, clip_model=clip_model, device=device)\n",
    "\n",
    "# Load the dataset\n",
    "dataset_root = try_paths(f\"/proj/nlp4adas/datasets/{DATASET_NAME}\", f\"/Users/s0000960/data/{DATASET_NAME}\")\n",
    "dataset = MultiLoader([\n",
    "    build_loader(dataset_root, clip_preprocess, batch_size=1, num_workers=1, split=split, dataset_name=DATASET_NAME) for split in SPLITS\n",
    "])\n",
    "means = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=\"cpu\")\n",
    "stds = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=\"cpu\")\n",
    "\n",
    "# Load the features\n",
    "feature_version = CLIP_VERSION.lower().replace(\"/\", \"-\")\n",
    "if USE_COSINE:\n",
    "    feature_version += \"_cosine\"\n",
    "feature_root = try_paths(\"../features\", \"/proj/nlp4adas/features\")\n",
    "img_feats = torch.cat([torch.load(f\"{feature_root}/{DATASET_NAME}_{feature_version}_{split}_img.pt\") for split in SPLITS],dim=0).to(device)\n",
    "lidar_feats = torch.cat([torch.load(f\"{feature_root}/{DATASET_NAME}_{feature_version}_{split}_lidar.pt\") for split in SPLITS],dim=0).to(device)\n",
    "joint_feats = img_feats + lidar_feats\n",
    "\n",
    "assert len(dataset) == len(img_feats) == len(lidar_feats) == len(joint_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2 = 6\n",
    "# image_prompts = [p.format(\"night\") for p in PERIOD_PROMPT_TEMPLATES]\n",
    "# image_prompts = [p.format(\"foggy not wet\") for p in WEATHER_PROMPT_TEMPLATES]\n",
    "image_prompts = [\"a small child on the sidewalk\", \"a kid walking with his parents\", \"a very tiny person\"]\n",
    "lidar_prompts = image_prompts\n",
    "SUBSAMPLING = 1  # avoid picking extremely similar samples\n",
    "OFFSET = 0\n",
    "img_idxs, pc_idxs, joint_idxs = get_topk_separate_prompts(image_prompts, lidar_prompts, K2, img_feats[OFFSET::SUBSAMPLING], lidar_feats[OFFSET::SUBSAMPLING])\n",
    "pc_idxs = pc_idxs * SUBSAMPLING + OFFSET\n",
    "img_idxs = img_idxs * SUBSAMPLING + OFFSET\n",
    "joint_idxs = joint_idxs * SUBSAMPLING + OFFSET\n",
    "\n",
    "PLOT_IMAGE = True\n",
    "PLOT_LIDAR = True\n",
    "PLOT_JOINT = False\n",
    "\n",
    "rows = int(PLOT_IMAGE) + int(PLOT_LIDAR) + int(PLOT_JOINT)\n",
    "\n",
    "fig = plt.figure(figsize=(10*K2,10*rows), dpi=200)\n",
    "width, height = 1/K2, 1/(rows+0.1)\n",
    "# ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "curr_row = 1\n",
    "if PLOT_IMAGE:\n",
    "    for i, idx in enumerate(img_idxs):\n",
    "        ax = fig.add_axes([i/K2, 1/rows, width, height])\n",
    "        ax.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "    curr_row+=1\n",
    "\n",
    "if PLOT_LIDAR:\n",
    "    for i, idx in enumerate(pc_idxs):\n",
    "        ax = fig.add_axes([i/K2, curr_row/rows, width, height])\n",
    "        ax.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "\n",
    "    curr_row+=1\n",
    "\n",
    "if PLOT_JOINT:\n",
    "    for i, idx in enumerate(joint_idxs):\n",
    "        img, pc = dataset[idx][:2]\n",
    "        # WHAT THE FUCK IS GOING ON HERE. I HAVE TO DO THIS TO GET THE RIGHT ORDERING\n",
    "        ax = fig.add_axes([i/K2, 0, width, height])\n",
    "        ax.imshow((img.permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "        \n",
    "        ax = fig.add_axes([i/K2 + 1.96/K2/3, 1.93/3/rows, width/3, height/3])\n",
    "        # draw a white box around the image\n",
    "        rect = patches.Rectangle((-10,4), 20, 16, alpha=1.0, facecolor='white')\n",
    "        ax.add_patch(rect)\n",
    "        # draw the point cloud\n",
    "        pc = pc[pc[:,0] < 20]\n",
    "        pc = pc[pc[:,1] < 10]\n",
    "        pc = pc[pc[:,1] > -10]\n",
    "        col = pc[:,3]\n",
    "        ax.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "        ax.axis(\"scaled\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_ylim(0, 20)\n",
    "        ax.set_xlim(-10, 10)\n",
    "    curr_row+=1\n",
    "\n",
    "print(pc_idxs)\n",
    "print(img_idxs)\n",
    "print(joint_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save some figures for the paper\n",
    "# for i, idx in enumerate(pc_idxs):\n",
    "#     plt.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(\"headlights_{}.png\".format(i), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classes =  [\"animal\", \"pedestrian\",] #  \"cyclist\", \"bus\", \"truck\", \"car\"]  # \"tree or bush\", \"three-wheeler\"]\n",
    "class_embeddings = []\n",
    "for cls_name in tqdm(zero_shot_classes, \"computing class embeddings...\"):\n",
    "    prompts = [template.format(cls_name) for template in OBJECT_PROMPT_TEMPLATES]\n",
    "    with torch.no_grad():\n",
    "        class_embeddings.append(clip_model.encode_text(clip.tokenize(prompts).to(device)).sum(axis=0, keepdim=True))\n",
    "class_embeddings = torch.cat(class_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE_IDXS = [\n",
    "#     61687,  # greenery\n",
    "#     0,      # bus\n",
    "#     1947,   # car\n",
    "#     8601,   # bus-car mix\n",
    "#     88888,  # nearby car\n",
    "#     58777,  # person biking\n",
    "#     113859, # moped\n",
    "#     13406,  # person walking unclear object\n",
    "#     96150,  # person with umbrella\n",
    "#     34170,  # person with backpack\n",
    "#     58854,  # doggo\n",
    "# ]\n",
    "SAMPLE_IDXS = [109737]\n",
    "lidar_feat = lidar_feats[SAMPLE_IDXS]\n",
    "image_feat = img_feats[SAMPLE_IDXS]\n",
    "joint_feat = joint_feats[SAMPLE_IDXS]\n",
    "with torch.no_grad():\n",
    "    lidar_scores_all = logit_img_txt(lidar_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "    image_scores_all = logit_img_txt(image_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "    joint_scores_all = logit_img_txt(joint_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "\n",
    "for i, sample_idx in enumerate(SAMPLE_IDXS):\n",
    "    img, pc = dataset[sample_idx][:2]\n",
    "    lidar_scores = lidar_scores_all[:, i]\n",
    "    image_scores = image_scores_all[:, i]\n",
    "    joint_scores = joint_scores_all[:, i]\n",
    "\n",
    "    fig = plt.figure(figsize=(7,5), dpi=150)\n",
    "\n",
    "    # Draw the image\n",
    "    ax = fig.add_axes([0, 0, 5/7, 1])\n",
    "    ax.imshow((img.permute(1,2,0)*stds + means).numpy())\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw the point cloud\n",
    "    ax = fig.add_axes([0.455, 0.698, 0.3, 0.3])\n",
    "    rect = patches.Rectangle((-10,0), 20, 20, alpha=1.0, facecolor='white')\n",
    "    ax.add_patch(rect)\n",
    "    pc = pc[pc[:,0] < 20]\n",
    "    pc = pc[pc[:,1] < 10]\n",
    "    pc = pc[pc[:,1] > -10]\n",
    "    col = pc[:,3]\n",
    "    ax.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "    ax.axis(\"scaled\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_ylim(0, 20)\n",
    "    ax.set_xlim(-10, 10)\n",
    "\n",
    "    # Draw the class bar chart\n",
    "    ax = fig.add_axes([5/7+0.001, 0.05, 2/7-0.001, 0.9])\n",
    "    # plot class scores as a horizontal bar chart with image lidar and joint scores side by side\n",
    "    # top down not down up\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) + 0.34, image_scores, height=0.15, color='#8DD376', label='image')\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) + 0.17, lidar_scores, height=0.15, color='#DE8B8A', label='lidar')\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) , joint_scores, height=0.15, color='#B172E0', label='joint')\n",
    "    ax.set_yticks(np.arange(len(zero_shot_classes))+0.57)\n",
    "    ax.set_yticklabels(zero_shot_classes)\n",
    "    ax.set_xticks([0.1, 0.4, 0.7, 1.0])\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.tick_params(axis=\"y\", direction=\"in\", pad=-142, labelsize=10, length=0)\n",
    "    ax.tick_params(axis=\"x\", direction='inout', length=5)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.spines.right.set_visible(False)\n",
    "    ax.spines.left.set_visible(False) \n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.set_title(\"Classification scores\")\n",
    "    ax.legend()\n",
    "    fig.savefig(\"{}.png\".format(sample_idx), bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIST_PAGE_IDX = 109737\n",
    "\n",
    "# # Draw the image\n",
    "# plt.imshow(dataset[FIST_PAGE_IDX][0].permute(1,2,0)*stds + means)\n",
    "# plt.axis(\"off\")\n",
    "# plt.savefig(\"front_page_image.png\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# # Draw the point cloud\n",
    "# plt.figure(figsize=(5,5), dpi=200)\n",
    "# pc  = dataset[FIST_PAGE_IDX][1].numpy()\n",
    "# pc = pc[pc[:,0] < 20]\n",
    "# pc = pc[pc[:,1] < 10]\n",
    "# pc = pc[pc[:,1] > -10]\n",
    "# col = pc[:,3]\n",
    "# plt.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "# plt.axis(\"scaled\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.ylim(0, 20)\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.savefig(\"front_page_lidar.png\", bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8474fbf7fa6f299d9ca87dcd7358dfc28aa95d8ec78802489d98a6cd3ecc0cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
