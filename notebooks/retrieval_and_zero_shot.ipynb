{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import clip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "sys.path.append('..')\n",
    "from lidarclip.loader import build_loader\n",
    "from lidarclip.helpers import MultiLoader, try_paths, get_topk, get_topk_separate_prompts, logit_img_txt\n",
    "from lidarclip.prompts import WEATHER_PROMPT_TEMPLATES, PERIOD_PROMPT_TEMPLATES, OBJECT_PROMPT_TEMPLATES, BUSY_PROMPTS, EMPTY_PROMPTS\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_VERSION = \"ViT-L/14\"\n",
    "USE_COSINE = False\n",
    "SPLITS = [\"val\", \"test\"]\n",
    "DATASET_NAME = \"once\"\n",
    "\n",
    "# Load clip\n",
    "clip_model, clip_preprocess = clip.load(CLIP_VERSION)\n",
    "get_topk = partial(get_topk, clip_model=clip_model, device=device)\n",
    "get_topk_separate_prompts = partial(get_topk_separate_prompts, clip_model=clip_model, device=device)\n",
    "\n",
    "# Load the dataset\n",
    "dataset_root = try_paths(f\"/proj/nlp4adas/datasets/{DATASET_NAME}\", f\"/Users/s0000960/data/{DATASET_NAME}\")\n",
    "dataset = MultiLoader([\n",
    "    build_loader(dataset_root, clip_preprocess, batch_size=1, num_workers=1, split=split, dataset_name=DATASET_NAME) for split in SPLITS\n",
    "])\n",
    "means = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=\"cpu\")\n",
    "stds = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=\"cpu\")\n",
    "\n",
    "# Load the features\n",
    "feature_version = CLIP_VERSION.lower().replace(\"/\", \"-\")\n",
    "if USE_COSINE:\n",
    "    feature_version += \"_cosine\"\n",
    "feature_root = try_paths(\"../features\", \"/proj/nlp4adas/features\")\n",
    "img_feats = torch.cat([torch.load(f\"{feature_root}/{DATASET_NAME}_{feature_version}_{split}_img.pt\") for split in SPLITS],dim=0).to(device)\n",
    "lidar_feats = torch.cat([torch.load(f\"{feature_root}/{DATASET_NAME}_{feature_version}_{split}_lidar.pt\") for split in SPLITS],dim=0).to(device)\n",
    "joint_feats = img_feats + lidar_feats\n",
    "\n",
    "assert len(dataset) == len(img_feats) == len(lidar_feats) == len(joint_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2 = 6\n",
    "image_prompts = [\"a photo of a blue car\"]\n",
    "lidar_prompts = image_prompts\n",
    "EXCLUDE_RANGE = 500  # increase this to avoid picking extremely similar samples\n",
    "cand_img_idxs, cand_pc_idxs, cand_joint_idxs = get_topk_separate_prompts(image_prompts, lidar_prompts, K2*EXCLUDE_RANGE, img_feats, lidar_feats)\n",
    "\n",
    "def filter_cands(cand_idxs, exclude_range):\n",
    "    # Go through the img_idxs in order and remove any duplicates within EXCLUDE_RANGE\n",
    "    idxs = []\n",
    "    exclude_idxs = set()\n",
    "    for idx in cand_idxs:\n",
    "        if idx in exclude_idxs:\n",
    "            continue\n",
    "        # Extend the exclude_idxs\n",
    "        exclude_idxs.update(range(idx-EXCLUDE_RANGE, idx+EXCLUDE_RANGE+1))\n",
    "        idxs.append(idx)\n",
    "        if len(idxs) == K2:\n",
    "            break\n",
    "    return np.array(idxs)\n",
    "\n",
    "img_idxs = filter_cands(cand_img_idxs, EXCLUDE_RANGE)\n",
    "pc_idxs = filter_cands(cand_pc_idxs, EXCLUDE_RANGE)\n",
    "joint_idxs = filter_cands(cand_joint_idxs, EXCLUDE_RANGE)\n",
    "\n",
    "PLOT_IMAGE = False\n",
    "PLOT_LIDAR = True\n",
    "PLOT_JOINT = False\n",
    "\n",
    "rows = int(PLOT_IMAGE) + int(PLOT_LIDAR) + int(PLOT_JOINT)\n",
    "\n",
    "fig = plt.figure(figsize=(10*K2,10*rows), dpi=200)\n",
    "width, height = 1/K2, 1/(rows+0.1)\n",
    "# ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "curr_row = 1\n",
    "if PLOT_IMAGE:\n",
    "    for i, idx in enumerate(img_idxs):\n",
    "        ax = fig.add_axes([i/K2, 1/rows, width, height])\n",
    "        ax.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "    curr_row+=1\n",
    "    print(img_idxs)\n",
    "\n",
    "if PLOT_LIDAR:\n",
    "    for i, idx in enumerate(pc_idxs):\n",
    "        ax = fig.add_axes([i/K2, curr_row/rows, width, height])\n",
    "        ax.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "    curr_row+=1\n",
    "    print(pc_idxs)  \n",
    "\n",
    "if PLOT_JOINT:\n",
    "    for i, idx in enumerate(joint_idxs):\n",
    "        img, pc = dataset[idx][:2]\n",
    "\n",
    "        # Draw the image\n",
    "        ax = fig.add_axes([i/K2, 0, width, height])\n",
    "        ax.imshow((img.permute(1,2,0)*stds + means).numpy())\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Draw a miniature of the point cloud in the top corner\n",
    "        ax = fig.add_axes([i/K2 + 1.96/K2/3, 1.93/3/rows, width/3, height/3])\n",
    "        rect = patches.Rectangle((-10,4), 20, 16, alpha=1.0, facecolor='white')\n",
    "        ax.add_patch(rect)\n",
    "        pc = pc[pc[:,0] < 20]\n",
    "        pc = pc[pc[:,1] < 10]\n",
    "        pc = pc[pc[:,1] > -10]\n",
    "        col = pc[:,3]\n",
    "        ax.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "        ax.axis(\"scaled\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_ylim(0, 20)\n",
    "        ax.set_xlim(-10, 10)\n",
    "    curr_row+=1\n",
    "    print(joint_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 13406\n",
    "img, pc = dataset[idx][:2]\n",
    "\n",
    "fig = plt.figure(figsize=(5,5), dpi=200)\n",
    "\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.imshow((img.permute(1,2,0)*stds + means).numpy())\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_axes([0.65, 0.65, 0.345, 0.345])\n",
    "# draw the point cloud\n",
    "pc = pc[pc[:,0] < 20]\n",
    "pc = pc[pc[:,1] < 10]\n",
    "pc = pc[pc[:,1] > -10]\n",
    "col = pc[:,3]\n",
    "ax.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "ax.axis(\"scaled\")\n",
    "# hide ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_ylim(0, 20)\n",
    "ax.set_xlim(-10, 10)\n",
    "\n",
    "fig.savefig(f\"img_{idx}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 65510 # 16367\n",
    "torch.save(lidar_feats[idx].clone(), f\"lidar_{idx}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save some figures for the paper\n",
    "# for i, idx in enumerate(pc_idxs):\n",
    "#     plt.imshow((dataset[idx][0].permute(1,2,0)*stds + means).numpy())\n",
    "#     plt.axis('off')\n",
    "#     plt.savefig(\"headlights_{}.png\".format(i), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZERO_SHOT_CLASSES =  [\"vegetation\", \"building\", \"animal\", \"pedestrian\", \"cyclist\", \"bus\", \"truck\", \"car\", \"three-wheeler\"]\n",
    "CLASS_EMBEDDINGS = []\n",
    "for cls_name in tqdm(ZERO_SHOT_CLASSES, \"computing class embeddings...\"):\n",
    "    prompts = [template.format(cls_name) for template in OBJECT_PROMPT_TEMPLATES]\n",
    "    with torch.no_grad():\n",
    "        CLASS_EMBEDDINGS.append(clip_model.encode_text(clip.tokenize(prompts).to(device)).sum(axis=0, keepdim=True))\n",
    "CLASS_EMBEDDINGS = torch.cat(CLASS_EMBEDDINGS, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_IDXS = [\n",
    "    61687,  # greenery\n",
    "    0,      # bus\n",
    "    1947,   # car\n",
    "    8601,   # bus-car mix\n",
    "    88888,  # nearby car\n",
    "    58777,  # person biking\n",
    "    113859, # moped\n",
    "    13406,  # person walking unclear object\n",
    "    96150,  # person with umbrella\n",
    "    34170,  # person with backpack\n",
    "    58854,  # doggo\n",
    "    109737, # three-wheeler\n",
    "]\n",
    "lidar_feat = lidar_feats[SAMPLE_IDXS]\n",
    "image_feat = img_feats[SAMPLE_IDXS]\n",
    "joint_feat = joint_feats[SAMPLE_IDXS]\n",
    "\n",
    "class_embeddings = CLASS_EMBEDDINGS\n",
    "zero_shot_classes = ZERO_SHOT_CLASSES\n",
    "\n",
    "with torch.no_grad():\n",
    "    lidar_scores_all = logit_img_txt(lidar_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "    image_scores_all = logit_img_txt(image_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "    joint_scores_all = logit_img_txt(joint_feat, class_embeddings, clip_model)[0].softmax(0)\n",
    "\n",
    "for i, sample_idx in enumerate(SAMPLE_IDXS):\n",
    "    img, pc = dataset[sample_idx][:2]\n",
    "    lidar_scores = lidar_scores_all[:, i]\n",
    "    image_scores = image_scores_all[:, i]\n",
    "    joint_scores = joint_scores_all[:, i]\n",
    "\n",
    "    fig = plt.figure(figsize=(8,5), dpi=150)\n",
    "\n",
    "    # Draw the image\n",
    "    ax = fig.add_axes([0, 0, 5/8, 1])\n",
    "    ax.imshow((img.permute(1,2,0)*stds + means).numpy())\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw the point cloud\n",
    "    ax = fig.add_axes([5/8-0.3 + 0.055, 0.698, 0.3, 0.3])\n",
    "    rect = patches.Rectangle((-10,0), 20, 20, alpha=1.0, facecolor='white')\n",
    "    ax.add_patch(rect)\n",
    "    pc = pc[pc[:,0] < 20]\n",
    "    pc = pc[pc[:,1] < 10]\n",
    "    pc = pc[pc[:,1] > -10]\n",
    "    col = pc[:,3]\n",
    "    ax.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "    ax.axis(\"scaled\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_ylim(0, 20)\n",
    "    ax.set_xlim(-10, 10)\n",
    "\n",
    "    # Draw the class bar chart\n",
    "    ax = fig.add_axes([5/8+0.001, 0.0, 3/8-0.001, 0.99])\n",
    "    # plot class scores as a horizontal bar chart with image lidar and joint scores side by side\n",
    "    # top down not down up\n",
    "    # draw vertical grid lines behind the bars\n",
    "    ax.grid(axis='x', linestyle='-', linewidth=0.5, color='black', alpha=0.3)    \n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_yticks(np.arange(len(zero_shot_classes))+0.65)\n",
    "    ax.set_yticklabels(zero_shot_classes, fontsize=8)\n",
    "    ax.set_xticks([0.1, 0.4, 0.7, 1.0])\n",
    "    ax.yaxis.tick_right()\n",
    "    # get the width of the axis in pixels\n",
    "    ax_width = ax.get_window_extent().width\n",
    "    ax.tick_params(axis=\"y\", direction=\"in\", pad=-ax_width/4+16, labelsize=10, length=0)\n",
    "    # Draw a white background around the tick labels\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_bbox(dict(facecolor='white', edgecolor='none', pad=2))\n",
    "        label.set_horizontalalignment('center')\n",
    "\n",
    "    ax.tick_params(axis=\"x\", direction='inout', length=0)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.spines.right.set_visible(False)\n",
    "    ax.spines.left.set_visible(False) \n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) + 0.36, image_scores, height=0.15, color='#8DD376', label='image')\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) + 0.18, lidar_scores, height=0.15, color='#DE8B8A', label='lidar')\n",
    "    ax.barh(np.arange(len(zero_shot_classes)) , joint_scores, height=0.15, color='#B172E0', label='joint')\n",
    "    ax.legend(loc='lower right', bbox_to_anchor=(1.1, 0.1), fontsize=8)\n",
    "    fig.savefig(\"zero_shot_{}.png\".format(sample_idx), bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIST_PAGE_IDX = 109737\n",
    "\n",
    "# # Draw the image\n",
    "# plt.imshow(dataset[FIST_PAGE_IDX][0].permute(1,2,0)*stds + means)\n",
    "# plt.axis(\"off\")\n",
    "# plt.savefig(\"front_page_image.png\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# # Draw the point cloud\n",
    "# plt.figure(figsize=(5,5), dpi=200)\n",
    "# pc  = dataset[FIST_PAGE_IDX][1].numpy()\n",
    "# pc = pc[pc[:,0] < 20]\n",
    "# pc = pc[pc[:,1] < 10]\n",
    "# pc = pc[pc[:,1] > -10]\n",
    "# col = pc[:,3]\n",
    "# plt.scatter(-pc[:,1], pc[:,0], s=0.1, c=col**0.3, cmap=\"coolwarm\")\n",
    "# plt.axis(\"scaled\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.ylim(0, 20)\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.savefig(\"front_page_lidar.png\", bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8474fbf7fa6f299d9ca87dcd7358dfc28aa95d8ec78802489d98a6cd3ecc0cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
